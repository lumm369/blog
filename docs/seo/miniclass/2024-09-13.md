---
id: "20240913"
slug: /20240913
title: 如何使用程序化 SEO 生成海量页面获取流量
tags:
  - 方式方法
---
日期：2024-09-13

今天的哥飞小课堂，用几个案例来讲解程序化 SEO 生成海量页面获取流量的方式。

先看流量，Similarweb 上面几个网站的最近 12 个月访问量，最大的 [distance. To](distance.to)  访问量 1297 万。

![](https://images.lummstudio.com/images/2024/09/miniclass/20240913-01.webp)

这些网站解决的需求是什么呢？其实是特别小的一个需求，甲地到乙地的距离是多少。如阿斯拜疆到德国距离是多少。Distance from Azerbaijan to Germany

这样两个地点，两两组合，就会有 N 多问题。仅仅从国家层面，全球 200 多个国家，就有四万多个问题了。再到省市区不同级别的地区，各自两两组合，几百万个问题都有了。

甚至离开地球，在宇宙尺度，也是有人会问问题的。

![](https://images.lummstudio.com/images/2024/09/miniclass/20240913-02.webp)

每一个地区，到另一个地区，都会有人好奇，距离是多少。

![](https://images.lummstudio.com/images/2024/09/miniclass/20240913-03.webp)

我们拿 [distance.to](distance.to) 这个网站来说，页面很好做，主体部分是地图，标记一下两个地区，连上线，再在地图上方浮层显示一些文字信息，整个页面就做好了。[https://www.distance.to/Germany/Azerbaijan](https://www.distance.to/Germany/Azerbaijan) .

![](https://images.lummstudio.com/images/2024/09/miniclass/20240913-04.webp)

谷歌收录了 [distance.to](distance.to) 129 万个页面。注意，并不是说这个网站服务器里有 129 万个 html 文件。这样的页面，都是统一的模板页面，只需要从数据库里取出地理位置数据，计算一下距离，然后把数据填充到模板里，每次用户访问时动态渲染出来就好了。

![](https://images.lummstudio.com/images/2024/09/miniclass/20240913-05.webp)

从前面的 site 结果看到，这个网站还做了多语言支持，并且用的是子域名的方式实现的。我们之前提到的多语言方式都是用子目录来实现的。两种方法都可以，但是哥飞建议，你一个新网站刚上线时，最好用子目录方式来实现，这样冷启动的成本更低。

![](https://images.lummstudio.com/images/2024/09/miniclass/20240913-06.webp)

即使是 canvas 这样的大站，也是用的子目录形式实现的多语言。

[https://www.canva.com/ai-image-generator/](https://www.canva.com/ai-image-generator/) 
[https://www.canva.com/ja_jp/ai-image-generator/](https://www.canva.com/ja_jp/ai-image-generator/) 
[https://www.canva.com/fr_fr/generateur-image-ia/](https://www.canva.com/fr_fr/generateur-image-ia/) 

所以不要因为我们今天分享了 distance.to，就觉得子域名形式更好。

两个地点之间，其实有很多需求，距离只是其中一个特别小的需求，但是你盯住这个这么小的需求，也能做出百万月访问量的网站。原因就是这类需求都可以做出海量页面。虽然每一个页面可能每一天只有几个几十个访问量，但是所有页面加起来，访问量就多了。

两地之间，更值钱的需求是交通，飞机、公路、轮船、铁路等等各种交通方式，直接卖票就是旅游网站的赚钱方式之一。

不知道大家发现没有，今天分享的 distance.to 生成页面的方式，跟之前大家理解的海量页面方式还不太一样。尤其是有了 AI 的加持后，大家以为的海量页面生成方式，就是让 AI 去回答海量的问题。但其实，不用 AI，也可以生成海量页面。

只需要你的数据库里有结构化的数据，就可以做成各种各样的模板，生成各种各样的页面。每一个页面都是盯着某一个真会有人搜索的需求去创建的。

结构化数据，这里划重点。如果你存储的都是纯文本数据，那么没有用的，一定要拆成结构化的数据，才能够按需组合，任意组合，生成各种各样的页面。

阿彪谈谈海量 SEO 页面以及最近的一些收获 [https://new.web.cafe/tutorial/detail/82ea980d818446bfbee3daea735126ea](https://new.web.cafe/tutorial/detail/82ea980d818446bfbee3daea735126ea) 
听完今天的小课堂，现在大家再去听彪哥将的海量页面 SEO 经验，可能就会更能听懂，更有收获了。

彪哥在演讲中给我们分享了一个找人找公司的网站，里边就有大量的页面，从人的维度，从公司的维度，从地点的维度，都能够生成海量页面。

这些页面是随便乱生成的吗？

不是的，是因为有人会这样搜索，所以才去生成相关的页面，期望我们的页面能够出现在真实用户搜索结果里，从而获得访问量。

之前有一次小课堂，哥飞分享的 [growjo.com](growjo.com) ，也是这类网站。

好，既然数据这么重要，那么数据怎么来呢？当然是从互联网中来。但是，没有哪个地方刚好就有你需要的一模一样的数据。所以一般都是你自己先分析好需求，规划好数据结构，然后按照需要，去找哪里可能有相关数据，你用爬虫去抓取，然后解析结构化数据。不过，这里注意一下，非公开数据，有版权数据，不要去抓取。

有时候一个地方不会有你需要的全部数据，你还需要去多个地方抓取，最后整合数据。

一般，如果我们去外部分享，提到了海量页面，一定会有人杠，你这不是垃圾网站吗？

我的回答是，只要能够帮助一部分人群解决某些特定需求，就不是垃圾网站。

他们会这么说，只是因为这个网站不是他的。吃不到的葡萄，都说是酸的。

谷歌有一个反垃圾机制，你不提供价值的网站，很难获取到流量了。能够拿到流量的网站，尤其是拿到大流量的网站，一定是能够给一部分人群提供价值的。

新站搞海量页面会分散权重吗？最后每个页面排名都很低吗？恰恰相反，因为有了海量有价值的页面的支撑，才会让你的新网站权重更高。注意，一定是有价值的网页。就是这些你上线的网页，需要能够在谷歌拿到排名，拿到曝光，获取到点击。

之前 6 月北京线下聚会时，Henry 分享了他的网站的案例，首页瞄准有一定优化难度的大搜索量关键词，然后通过二级页面和大量的三级页面，不断的获取小词的排名、曝光、点击，进而带动了上一级页面的权重，最后让首页拿到了相关关键词的排名。下面的这条流量增长曲线就说明了，这个内容策略是有效的。

![](https://images.lummstudio.com/images/2024/09/miniclass/20240913-07.webp)

[https://mp.weixin.qq.com/s/Dgf_3fJmNrBWj6u76essUw](https://mp.weixin.qq.com/s/Dgf_3fJmNrBWj6u76essUw) 

怎么让搜索引擎爬虫能够爬取到你的海量页面，可以看看上面这篇文章。

还有个问题，大家很关心，现在还可以做这样的网站吗？

那么你就要去挖掘相关需求了，而不是仅仅盯着哥飞今天分享的两地距离这个需求去做。重要的是学会这种建站思路，然后再去挖掘可以用这个建站思路做站的需求。

提问环节：
1、这种海量页面，新站的话，一天上多少个页面合适？

回答：每一个站的情况都不同，一般来讲，前期少量测试，每天 10 个页面，看看爬虫是否能够全部抓取，以及抓了之后是否会出词。这一步目的是测试你的模板页面 SEO 做得到底好不好。根据 GSC 后台反馈的数据，不断调整页面。直到你给出的页面，谷歌爬虫都能够抓取，并且都出词了，那就说明你的页面调整得差不多了。

接下来，就可以增大生成页面的数量，每天 100 个看看谷歌爬虫是否吃得下。

如果也是能吃下去，并且也有出词，那就改成每天 200 个，300 个，500 个，1000 个。

2、判断一个页面需不需要生成，数据来源和依据一般是什么？是不是当前站点的搜索后台的搜索情况，或者按照以前的搜索意图去分析？

回答：刚才课堂里已经讲了，因为有人会在搜索引擎搜索相关关键词，我们才去做相关的页面。

3、像这种海量页面，做多语言的时候进行翻译有什么低成本的方法不？

回答：拿距离网站举例，多语言分两部分：1 界面 UI 文案多语言，这里一次翻译，多次可用，不用多说；2 数据多语言，一般是在录入数据时，就自动调用相关翻译接口，生成多语言数据。

4、类似 lobe-chat 这种开源的聊天助理软件，怎么赚钱？

回答：给个人免费使用，商用要付费的。

5、距离的这个网站用是什么数据结构？怎么去切分字段更加高效呢？

回答：大概猜测，需要有一个地点数据表，记录了全球各个国家各个地区的基本信息、从属关系，以及每一个地区的中心点的 GPS 坐标。然后还可以有一张表，存储计算好的两地之间的距离数据，不过这张表也可以不要，临时计算也可以。